{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKWujuA5Tx-a"
      },
      "source": [
        "# 1.0 Install Packages and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4i90qdpMj5A",
        "outputId": "97b34411-2d52-4211-d474-a1c1e74d3351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl rouge_score wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mZkXodFUSj5O"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    GenerationConfig\n",
        ")\n",
        "from tqdm import tqdm\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from huggingface_hub import interpreter_login\n",
        "from huggingface_hub import login\n",
        "import wandb\n",
        "import os\n",
        "\n",
        "# # Login to HuggingFace\n",
        "# interpreter_login()\n",
        "\n",
        "# Login to Huggingface\n",
        "api_token = \"<API KEY HERE>\"\n",
        "login(token=api_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCJlpijUwra",
        "outputId": "6b2395c5-65ba-4137-c3e1-82d794027808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m0132114\u001b[0m (\u001b[33m0132114-uow-malaysia\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully logged into Weights & Biases!\n"
          ]
        }
      ],
      "source": [
        "# Login to weights and biases (to track training metrics)\n",
        "# # wandb.login()\n",
        "# # %env WANDB_PROJECT=Fine-Tune-QLoRA\n",
        "\n",
        "#---------------------------------------------------------------\n",
        "\n",
        "# Set your W&B API key here\n",
        "os.environ[\"WANDB_API_KEY\"] = \"<API KEY HERE>\"\n",
        "\n",
        "# Log in to W&B\n",
        "wandb.login()\n",
        "\n",
        "# Set your W&B project\n",
        "os.environ[\"WANDB_PROJECT\"] = \"Fine-Tune-QLoRA\"\n",
        "\n",
        "print(\"Successfully logged into Weights & Biases!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAmziml9T7oH"
      },
      "source": [
        "# 2.0 Load the Processed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPeWtCaH3O_C",
        "outputId": "fc600c33-ea7a-4aec-8eef-886979159000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Datasets loaded!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = load_from_disk('/content/drive/My Drive/mental_health_dataset/hf_train_dataset')\n",
        "val_dataset = load_from_disk('/content/drive/My Drive/mental_health_dataset/hf_val_dataset')\n",
        "\n",
        "print(\"Datasets loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff104-aetIW4",
        "outputId": "ceb2c648-37c4-4c81-cf79-7a24b5cc36ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 561\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 70\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)\n",
        "print(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvLB9ETyg11l"
      },
      "source": [
        "# 3.0 Configure Bits and Bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "kDw9zGwsUU4C"
      },
      "outputs": [],
      "source": [
        "# Ensure the computation uses 16-bit floating-point (reduce memory usage, speed up training)\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "# Configure Bits and Bytes to load the model in 4-bit (quantized)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True, # Load the weights in 4 bit\n",
        "        bnb_4bit_quant_type='nf4', # Use nf4 datatype\n",
        "        bnb_4bit_compute_dtype=compute_dtype, # Uses 16-bit floating-point (float16)\n",
        "        bnb_4bit_use_double_quant=True, # Enable double quantization\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b50ZeZ1uhlUA"
      },
      "source": [
        "# 4.0 Load the Pretrained Model in 4-bit (Quantized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "494N5E2XUVU3"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model, 'meta-llama/Llama-3.2-1B-Instruct' required authorization\n",
        "base_model_name = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "device_map = \"auto\" #{\"\": 0}\n",
        "base_model = AutoModelForCausalLM.from_pretrained(base_model_name,\n",
        "                                                      device_map=device_map,\n",
        "                                                      quantization_config=bnb_config, # To load in 4-bit and double quantization\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_cache = False,\n",
        "                                                      use_auth_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tClGqr6WiqBw"
      },
      "source": [
        "# 5.0 Configure the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "L96ZHudqZ5b5"
      },
      "outputs": [],
      "source": [
        "# Configure the tokenizer, use left-padding to optimize memory usage during training.\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name,\n",
        "                                          trust_remote_code=True,\n",
        "                                          padding_side=\"left\",\n",
        "                                          add_eos_token=True,\n",
        "                                          add_bos_token=True,\n",
        "                                          use_fast=False)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgdsxp86ZtMf"
      },
      "source": [
        "# 6.0 Test the Base Model's Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwwDtJb6VarA",
        "outputId": "dbe126ec-4ab9-4061-b787-4a94bce7778d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE MODEL RESPONSE \n",
            "============================================== \n",
            " I'm here to listen. It's important to acknowledge your feelings and work through them in a safe space. Can you tell me more about what happened? What was the situation like? How did it make you feel? And how does it affect you now?\n"
          ]
        }
      ],
      "source": [
        "# Insert prompt\n",
        "prompt = \"Something happened this summer that I cannot forgive myself for. When I think about what happened, I feel ashamed and guilty even though my loved ones forgave me.\"\n",
        "\n",
        "# Format the prompt\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful mental health therapist.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# Apply chat template\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False, # Keep text as string\n",
        "    add_generation_prompt=True # Adds additional instructions (if needed)\n",
        ")\n",
        "\n",
        "# Tokenize the text\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(base_model.device)\n",
        "\n",
        "# Generate response\n",
        "generated_ids = base_model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Get the generated tokens\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "# Decode the tokens into text\n",
        "base_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"BASE MODEL RESPONSE \\n============================================== \\n\", base_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arfVBXVy3rXY"
      },
      "source": [
        "# 8.0 Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpC6IeBfCF-f"
      },
      "source": [
        "## 8.1 Configure LoRA and Initialize LoRA adapter (LoRA trainable version of the model)\n",
        "- LoRA adapter: 2 smaller matrices that are fine tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygwPdCcV7BOE",
        "outputId": "f8bc0288-80cb-4ecc-fc6c-8ec90c5381fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 5,898,240 || all params: 499,931,008 || trainable%: 1.1798\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# Configure the LoRA parameters\n",
        "config = LoraConfig(\n",
        "    r=64, # Rank, no. of parameters trained (E.g., for a 512x512 (262144) matrix, if rank = 64, the LoRA adapter uses 512x64 and 64x512 parameters.)\n",
        "    lora_alpha=128, # Alpha, how much the model adapts to the new training data.\n",
        "    target_modules=[\n",
        "        'q_proj',\n",
        "        'k_proj',\n",
        "        'v_proj'\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Enable gradient checkpointing to reduce memory usage during fine-tuning\n",
        "base_model.gradient_checkpointing_enable()\n",
        "\n",
        "# Prepare the base model for QLoRA\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n",
        "\n",
        "# Get the LoRA trainable version of the model (LoRA adapter)\n",
        "peft_model = get_peft_model(base_model, config)\n",
        "\n",
        "# Check the no. of trainable parameters\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwi2tegNCXVg"
      },
      "source": [
        "## 8.2 Define 'TrainingArguments' and Create 'Trainer' Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7btlBpaD9qOa"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "\n",
        "# Define the output directory\n",
        "output_model_name = f'Qwen2.5-Mental-Health-Bot-0.5B-{time.strftime(\"%Y%m%d\")}'\n",
        "output_dir = f'./{output_model_name}'\n",
        "\n",
        "# Define the training arguments\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    warmup_steps=25, # For the first n steps, learning rate slowly increases\n",
        "    per_device_train_batch_size=4,\n",
        "    # per_device_eval_batch_size=2, # evaluation batch size\n",
        "    gradient_accumulation_steps=4, # Updates model every n batch\n",
        "    # max_steps=1500, # maximum no. of steps\n",
        "    num_train_epochs=10,\n",
        "    learning_rate=2e-5, #(0.00002)\n",
        "    optim=\"paged_adamw_8bit\", # Optimizer type used to update weights\n",
        "    logging_steps=10, # Log the loss output every n steps\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10, # Save model every 500 steps\n",
        "    # eval_strategy=\"steps\", # evaluation strategy (High GPU RAM)\n",
        "    # eval_steps = 500, # evaluation steps (High GPU RAM)\n",
        "    do_eval=True,\n",
        "    gradient_checkpointing=True,\n",
        "    report_to=\"wandb\",\n",
        "    overwrite_output_dir = 'True',\n",
        "    group_by_length=True,\n",
        "    # max_eval_samples=1000, # no. of evaluation samples (High GPU RAM)\n",
        "    # fp16=True,\n",
        ")\n",
        "\n",
        "# Disable caching to save memory\n",
        "peft_model.config.use_cache = False\n",
        "\n",
        "# Create the 'Trainer' instance\n",
        "peft_trainer = transformers.Trainer(\n",
        "    model=peft_model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    args=peft_training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulJGL1tiCjVo"
      },
      "source": [
        "## 8.3 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "oKA5Ixq4gsUg"
      },
      "outputs": [],
      "source": [
        "# To save memory\n",
        "del base_model\n",
        "del bnb_config\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rcCnrtYSAqum",
        "outputId": "1e637ae3-097c-4b38-bc55-63f1c5572cfe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250105_141617-1xhfpqjw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA/runs/1xhfpqjw' target=\"_blank\">./Qwen2.5-Mental-Health-Bot-0.5B-20250105</a></strong> to <a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA' target=\"_blank\">https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA/runs/1xhfpqjw' target=\"_blank\">https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA/runs/1xhfpqjw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [350/350 17:23, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.053100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.989800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.850100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.644100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.623800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.548100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.598700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.567600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.515900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.575700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.504100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.527700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.532600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.501700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>2.547600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.442900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>2.498500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>2.488900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.512600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.513500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.502300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.504100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.495400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>2.494700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.526300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.461600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.475400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▂▂▂▁▂▁▂▁▁▁▁▁▂▁▁▁█▁▁▁▁▁▂▁▂▁▁▁▁▁▂▁▂▁</td></tr><tr><td>train/learning_rate</td><td>▄▇███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▅▄▃▄▂▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>3836708377468416.0</td></tr><tr><td>train/epoch</td><td>9.73759</td></tr><tr><td>train/global_step</td><td>350</td></tr><tr><td>train/grad_norm</td><td>0.89866</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>2.4754</td></tr><tr><td>train_loss</td><td>2.58979</td></tr><tr><td>train_runtime</td><td>1052.8733</td></tr><tr><td>train_samples_per_second</td><td>5.328</td></tr><tr><td>train_steps_per_second</td><td>0.332</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">./Qwen2.5-Mental-Health-Bot-0.5B-20250105</strong> at: <a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA/runs/1xhfpqjw' target=\"_blank\">https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA/runs/1xhfpqjw</a><br> View project at: <a href='https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA' target=\"_blank\">https://wandb.ai/0132114-uow-malaysia/Fine-Tune-QLoRA</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250105_141617-1xhfpqjw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Start training the model\n",
        "peft_trainer.train()\n",
        "\n",
        "# Stop reporting to wandb\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7doyb2NIjiFA"
      },
      "outputs": [],
      "source": [
        "# Free memory for merging weights\n",
        "# del peft_trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTIShiCAC4um"
      },
      "source": [
        "# 9.0 Merge Fine Tuned LoRA Adapter to the Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "iMcLJ4UHh8Kd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Configure Bits and Bytes to load the model in 4-bit (quantized)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True, # Load the weights in 4 bit\n",
        "        bnb_4bit_quant_type='nf4',\n",
        "        bnb_4bit_compute_dtype=compute_dtype, # Uses 16-bit floating-point (float16)\n",
        "        bnb_4bit_use_double_quant=True, # Enable double quantization\n",
        "    )\n",
        "\n",
        "base_model_name = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "base_model = AutoModelForCausalLM.from_pretrained(base_model_name,\n",
        "                                                      device_map='auto',\n",
        "                                                      quantization_config=bnb_config,\n",
        "                                                      trust_remote_code=True,\n",
        "                                                      use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FF_4NDIVivJG"
      },
      "outputs": [],
      "source": [
        "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_name, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
        "eval_tokenizer.pad_token = eval_tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "jKnyuR9kj91V"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "final_dir = f'/content/{output_model_name}/checkpoint-350'\n",
        "\n",
        "# Get the LoRA adapter\n",
        "ft_model = PeftModel.from_pretrained(base_model, final_dir, torch_dtype=torch.float16, is_trainable=False)\n",
        "\n",
        "# Merge the LoRA adapter with the base model and save the merged model\n",
        "lora_merged_model = ft_model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EL0NJZvbfqQ"
      },
      "source": [
        "# 10.0 Test the Fine Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fVdfZCaWEQA",
        "outputId": "51b60aa6-1729-41fb-9885-35669a62d97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE RESPONSE \n",
            "============================================== \n",
            " I'm here to listen. It's important to acknowledge your feelings and work through them in a safe space. Can you tell me more about what happened? What was the situation like? How did it make you feel? And how does it affect you now?\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------- \n",
            "\n",
            "FINE TUNED RESPONSE \n",
            "============================================== \n",
            " I'm sorry to hear that you're feeling this way. It's important to remember that everyone makes mistakes and it's okay to feel shame or guilty when we do. However, it's also important to take responsibility for our actions and work on learning from them.\n",
            "\n",
            "One way to start is by acknowledging your feelings of shame and guilt. You can write down your thoughts and feelings in a journal or talk to someone who understands what you're going through.\n",
            "\n",
            "Another option is to seek support from friends, family members, or professionals like a therapist. They can provide guidance and help you process your emotions and learn new coping mechanisms.\n",
            "\n",
            "It may also be helpful to focus on the things you can control in your life, such as your own choices and decisions. This can give you a sense of control and reduce the impact of past mistakes.\n",
            "\n",
            "Remember, it's okay to make mistakes and learn from them, but it's equally important to move forward and find ways to grow and improve.\n"
          ]
        }
      ],
      "source": [
        "# Insert prompt\n",
        "prompt = \"Something happened this summer that I cannot forgive myself for. When I think about what happened, I feel ashamed and guilty even though my loved ones forgave me.\"\n",
        "\n",
        "# Format the prompt\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful mental health therapist.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# Apply chat template\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False, # Keep text as string\n",
        "    add_generation_prompt=True # Adds additional instructions (if needed)\n",
        ")\n",
        "\n",
        "# Tokenize the text\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(lora_merged_model.device)\n",
        "\n",
        "# Generate response\n",
        "generated_ids = lora_merged_model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Get the generated tokens\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "# Decode the tokens into text\n",
        "ft_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"BASE RESPONSE \\n============================================== \\n\", base_response)\n",
        "print(\"\\n--------------------------------------------------------------------------------------------------------------------- \\n\")\n",
        "print(\"FINE TUNED RESPONSE \\n============================================== \\n\", ft_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7fQV-3WBB9z"
      },
      "source": [
        "# 11.0 Push to HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "6b464a01b40e48039857d0a62b512c15",
            "bf2dceca4f274adc8d755f55c2ba4dcd",
            "db28146d0ed54e7e9447e96972ec0b41",
            "af0f2aee482c49ba8175fff860afe0aa",
            "ccf8728cc64843c88a18e2c6b9786c51",
            "96b387aa9ef443a7a029f8841d350d4d",
            "184d17d9611341fea47cef2381ca19f0",
            "7a61b3f382f34075a95a8e0fad79796d",
            "63734c4f75eb4eaf98b855c497f0361c",
            "cff7daae67a14f539da1e5610e16e453",
            "77b8b3c52e664ca0b492cd32739e76eb",
            "57b531ec1a564ba29f64091fcaaf5fd6",
            "1262caea691c45a2bffc53aca85386e5",
            "4d9bd8d67c344139a7efc7d7818c0566",
            "073b77730ebc4efba81509e37037fcc7",
            "9668d411fed043c79a14ef38cb0e2799",
            "9660614e9bae417eb5119c9e54f9f0dd",
            "6b86d8b2a8f7438b9dfdc4d37dbf9186",
            "d3c8651f0f394d6db905e9fb3e7d8459",
            "f295864cb79f4677a0c4fada13c12717",
            "ce94f48400f44b7583d35ece900a60a4",
            "ca4a04fa9b1e4548be57083952a51c7c"
          ]
        },
        "id": "XEOQdvxHoKuX",
        "outputId": "a571f118-6de6-40b2-eb5b-930993bbfad2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b464a01b40e48039857d0a62b512c15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/457M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57b531ec1a564ba29f64091fcaaf5fd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/hezronling/Qwen2.5-Mental-Health-Bot-0.5B-v1.0/commit/fffe7ba0bd957634b0dc83e077c3aea25768e9ec', commit_message='Upload tokenizer', commit_description='', oid='fffe7ba0bd957634b0dc83e077c3aea25768e9ec', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hezronling/Qwen2.5-Mental-Health-Bot-0.5B-v1.0', endpoint='https://huggingface.co', repo_type='model', repo_id='hezronling/Qwen2.5-Mental-Health-Bot-0.5B-v1.0'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lora_merged_model.save_pretrained(\"merged\",safe_serialization=True)\n",
        "tokenizer.save_pretrained(\"merged\")\n",
        "\n",
        "#push merged model to the hub\n",
        "lora_merged_model.push_to_hub(\"Qwen2.5-Mental-Health-Bot-0.5B-v1.0\") # the name of the model you want\n",
        "tokenizer.push_to_hub(\"Qwen2.5-Mental-Health-Bot-0.5B-v1.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqB4hyN7BjdA"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wuv3lbu6IiX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "073b77730ebc4efba81509e37037fcc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce94f48400f44b7583d35ece900a60a4",
            "placeholder": "​",
            "style": "IPY_MODEL_ca4a04fa9b1e4548be57083952a51c7c",
            "value": " 5.17k/5.17k [00:00&lt;00:00, 253kB/s]"
          }
        },
        "1262caea691c45a2bffc53aca85386e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9660614e9bae417eb5119c9e54f9f0dd",
            "placeholder": "​",
            "style": "IPY_MODEL_6b86d8b2a8f7438b9dfdc4d37dbf9186",
            "value": "README.md: 100%"
          }
        },
        "184d17d9611341fea47cef2381ca19f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d9bd8d67c344139a7efc7d7818c0566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3c8651f0f394d6db905e9fb3e7d8459",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f295864cb79f4677a0c4fada13c12717",
            "value": 5174
          }
        },
        "57b531ec1a564ba29f64091fcaaf5fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1262caea691c45a2bffc53aca85386e5",
              "IPY_MODEL_4d9bd8d67c344139a7efc7d7818c0566",
              "IPY_MODEL_073b77730ebc4efba81509e37037fcc7"
            ],
            "layout": "IPY_MODEL_9668d411fed043c79a14ef38cb0e2799"
          }
        },
        "63734c4f75eb4eaf98b855c497f0361c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b464a01b40e48039857d0a62b512c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf2dceca4f274adc8d755f55c2ba4dcd",
              "IPY_MODEL_db28146d0ed54e7e9447e96972ec0b41",
              "IPY_MODEL_af0f2aee482c49ba8175fff860afe0aa"
            ],
            "layout": "IPY_MODEL_ccf8728cc64843c88a18e2c6b9786c51"
          }
        },
        "6b86d8b2a8f7438b9dfdc4d37dbf9186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77b8b3c52e664ca0b492cd32739e76eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a61b3f382f34075a95a8e0fad79796d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9660614e9bae417eb5119c9e54f9f0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9668d411fed043c79a14ef38cb0e2799": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b387aa9ef443a7a029f8841d350d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0f2aee482c49ba8175fff860afe0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff7daae67a14f539da1e5610e16e453",
            "placeholder": "​",
            "style": "IPY_MODEL_77b8b3c52e664ca0b492cd32739e76eb",
            "value": " 457M/457M [00:12&lt;00:00, 46.5MB/s]"
          }
        },
        "bf2dceca4f274adc8d755f55c2ba4dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b387aa9ef443a7a029f8841d350d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_184d17d9611341fea47cef2381ca19f0",
            "value": "model.safetensors: 100%"
          }
        },
        "ca4a04fa9b1e4548be57083952a51c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccf8728cc64843c88a18e2c6b9786c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce94f48400f44b7583d35ece900a60a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff7daae67a14f539da1e5610e16e453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c8651f0f394d6db905e9fb3e7d8459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db28146d0ed54e7e9447e96972ec0b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a61b3f382f34075a95a8e0fad79796d",
            "max": 457346522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63734c4f75eb4eaf98b855c497f0361c",
            "value": 457346522
          }
        },
        "f295864cb79f4677a0c4fada13c12717": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
