{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.73758865248227,
  "eval_steps": 500,
  "global_step": 350,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.28368794326241137,
      "grad_norm": 1.79973566532135,
      "learning_rate": 8.000000000000001e-06,
      "loss": 3.08,
      "step": 10
    },
    {
      "epoch": 0.5673758865248227,
      "grad_norm": 1.805594563484192,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 3.0531,
      "step": 20
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 2.3420932292938232,
      "learning_rate": 1.9692307692307696e-05,
      "loss": 2.9898,
      "step": 30
    },
    {
      "epoch": 1.1134751773049645,
      "grad_norm": 1.80687415599823,
      "learning_rate": 1.907692307692308e-05,
      "loss": 2.8501,
      "step": 40
    },
    {
      "epoch": 1.397163120567376,
      "grad_norm": 1.3082557916641235,
      "learning_rate": 1.8461538461538465e-05,
      "loss": 2.759,
      "step": 50
    },
    {
      "epoch": 1.6808510638297873,
      "grad_norm": 2.6840972900390625,
      "learning_rate": 1.784615384615385e-05,
      "loss": 2.6441,
      "step": 60
    },
    {
      "epoch": 1.9645390070921986,
      "grad_norm": 1.0861492156982422,
      "learning_rate": 1.7230769230769234e-05,
      "loss": 2.6752,
      "step": 70
    },
    {
      "epoch": 2.226950354609929,
      "grad_norm": 1.5026509761810303,
      "learning_rate": 1.6615384615384618e-05,
      "loss": 2.555,
      "step": 80
    },
    {
      "epoch": 2.5106382978723403,
      "grad_norm": 0.7448379397392273,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.6238,
      "step": 90
    },
    {
      "epoch": 2.794326241134752,
      "grad_norm": 0.872710108757019,
      "learning_rate": 1.5384615384615387e-05,
      "loss": 2.6008,
      "step": 100
    },
    {
      "epoch": 3.0567375886524824,
      "grad_norm": 0.8990829586982727,
      "learning_rate": 1.4769230769230772e-05,
      "loss": 2.5481,
      "step": 110
    },
    {
      "epoch": 3.3404255319148937,
      "grad_norm": 0.8632179498672485,
      "learning_rate": 1.4153846153846156e-05,
      "loss": 2.5987,
      "step": 120
    },
    {
      "epoch": 3.624113475177305,
      "grad_norm": 1.0602020025253296,
      "learning_rate": 1.353846153846154e-05,
      "loss": 2.5676,
      "step": 130
    },
    {
      "epoch": 3.9078014184397163,
      "grad_norm": 1.8307652473449707,
      "learning_rate": 1.2923076923076925e-05,
      "loss": 2.5159,
      "step": 140
    },
    {
      "epoch": 4.170212765957447,
      "grad_norm": 1.1780030727386475,
      "learning_rate": 1.230769230769231e-05,
      "loss": 2.5757,
      "step": 150
    },
    {
      "epoch": 4.453900709219858,
      "grad_norm": 1.3994282484054565,
      "learning_rate": 1.1692307692307694e-05,
      "loss": 2.5041,
      "step": 160
    },
    {
      "epoch": 4.73758865248227,
      "grad_norm": 0.8407700061798096,
      "learning_rate": 1.1076923076923079e-05,
      "loss": 2.5277,
      "step": 170
    },
    {
      "epoch": 5.0,
      "grad_norm": 9.928706169128418,
      "learning_rate": 1.0461538461538463e-05,
      "loss": 2.508,
      "step": 180
    },
    {
      "epoch": 5.283687943262412,
      "grad_norm": 0.8912495374679565,
      "learning_rate": 9.846153846153848e-06,
      "loss": 2.5326,
      "step": 190
    },
    {
      "epoch": 5.567375886524823,
      "grad_norm": 0.9734830260276794,
      "learning_rate": 9.230769230769232e-06,
      "loss": 2.5017,
      "step": 200
    },
    {
      "epoch": 5.851063829787234,
      "grad_norm": 1.1810985803604126,
      "learning_rate": 8.615384615384617e-06,
      "loss": 2.5476,
      "step": 210
    },
    {
      "epoch": 6.113475177304965,
      "grad_norm": 0.9655326008796692,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.4429,
      "step": 220
    },
    {
      "epoch": 6.397163120567376,
      "grad_norm": 1.318030595779419,
      "learning_rate": 7.384615384615386e-06,
      "loss": 2.4985,
      "step": 230
    },
    {
      "epoch": 6.680851063829787,
      "grad_norm": 1.5575700998306274,
      "learning_rate": 6.76923076923077e-06,
      "loss": 2.4889,
      "step": 240
    },
    {
      "epoch": 6.964539007092198,
      "grad_norm": 0.9296329617500305,
      "learning_rate": 6.153846153846155e-06,
      "loss": 2.5126,
      "step": 250
    },
    {
      "epoch": 7.226950354609929,
      "grad_norm": 1.5707283020019531,
      "learning_rate": 5.538461538461539e-06,
      "loss": 2.5135,
      "step": 260
    },
    {
      "epoch": 7.51063829787234,
      "grad_norm": 0.9405405521392822,
      "learning_rate": 4.923076923076924e-06,
      "loss": 2.508,
      "step": 270
    },
    {
      "epoch": 7.794326241134752,
      "grad_norm": 1.0902154445648193,
      "learning_rate": 4.307692307692308e-06,
      "loss": 2.5023,
      "step": 280
    },
    {
      "epoch": 8.056737588652481,
      "grad_norm": 0.8468345403671265,
      "learning_rate": 3.692307692307693e-06,
      "loss": 2.5041,
      "step": 290
    },
    {
      "epoch": 8.340425531914894,
      "grad_norm": 0.9448257088661194,
      "learning_rate": 3.0769230769230774e-06,
      "loss": 2.4954,
      "step": 300
    },
    {
      "epoch": 8.624113475177305,
      "grad_norm": 1.3795151710510254,
      "learning_rate": 2.461538461538462e-06,
      "loss": 2.4947,
      "step": 310
    },
    {
      "epoch": 8.907801418439716,
      "grad_norm": 1.464802861213684,
      "learning_rate": 1.8461538461538465e-06,
      "loss": 2.4598,
      "step": 320
    },
    {
      "epoch": 9.170212765957446,
      "grad_norm": 1.1472139358520508,
      "learning_rate": 1.230769230769231e-06,
      "loss": 2.5263,
      "step": 330
    },
    {
      "epoch": 9.453900709219859,
      "grad_norm": 1.617315411567688,
      "learning_rate": 6.153846153846155e-07,
      "loss": 2.4616,
      "step": 340
    },
    {
      "epoch": 9.73758865248227,
      "grad_norm": 0.8986579179763794,
      "learning_rate": 0.0,
      "loss": 2.4754,
      "step": 350
    }
  ],
  "logging_steps": 10,
  "max_steps": 350,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3836708377468416.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
